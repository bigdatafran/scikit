{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass clasificación.\n",
    "(multiclases)=\n",
    "## Introducción.\n",
    "```{index} One-vs-Rest, One-vs-One\n",
    "```\n",
    "\n",
    "No todos los modelos predictivos de clasificación, soportan una clasificación multiclase, y en este sentido algoritmos muy importantes por su uso como Perceptron, Regresión logística y Support Vector Machine fueron diseñados para hacer una clasificación binaria, es decir con tan sólo dos clases a predecir.\n",
    "\n",
    "Debido a esta restricción que se tiene para este tipo de algoritmos, se puede diseñar una aproximación a una clasificación multiclase utilizando clasificación binaria, dividiendo la clasificación múltiple en varias clasificaciones binarias y hacer un ajuste binario sobre estas últimas. Para hacer esto último, se han ideado dos enfoques o estrategias diferentes denominados One-vs-Rest y One-vs-One. En este apartado vamos a desarrollar estas dos estrategias, y se desarrollará algún ejemplo que permita clarificar cómo se pueden usar.\n",
    "\n",
    "## One-Vs-Rest para clasificación múltiple.\n",
    "\n",
    "La clasificación One-Vs-Rest (de forma abreviada OvR) también es conocida como One-vs-All (de forma abreviada OvA), se utiliza para resolver un problema de clasificación múltiple mediante varios problemas de clasificación binaria. En este sentido lo que se hace es entrenar un modelo de  clasificación binaria de cada clase sobre el resto, es decir si por ejemplo la variable de clasificación está constituida por tres clases: rojo, verde y azul; entonces se generarían tres modelo de clasificación binaria:\n",
    "\n",
    "* Clasificación binaria de rojo frente al resto [verde, azul]\n",
    "\n",
    "* Clasificación binaria de verde frente al resto [rojo, azul]\n",
    "\n",
    "* Clasificación binaria de azul frente al resto [verde, rojo]\n",
    "\n",
    "Por lo tanto en este tipo de problemas, se requiere ajustar un modelo por cada clase constituyente de la variable de clasificación, lo cual puede ocasionar una ralentización importante del proceso.\n",
    "\n",
    "Con este enfoque lo que se requiere es que cada uno de los modelos, prediga una probabilidad de pertenencia de una observación a una determinada clase, y entonces la decisión a tomar es clasificar una observación en la clase que se haya obtenido una mayor probabilidad. Por lo tanto, este procedimiento puede ser utilizado en los algoritmos que predigan una probabilidad de pertenencia a una clase, como pueden ser la *regresión logística* o *Perceptron*. \n",
    "\n",
    "La clase de scikit Learn *LogisticRegression* tiene un hiparámetro denominado *multiclase* que si se le da un valor de 'ovr' realiza una clasificación multiclase de tipo One-vs-Rest. Veamos a continuación un ejemplo utilizando un conjunto de datos generados de forma artificial con la función *make_classification*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracidad media: 0.686 (0.036)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# generamos los datos con un total de tres clases (n_classes=3)\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5,\n",
    "n_classes=3, random_state=1)\n",
    "# definimos el modelo para clasificación múltiple multi_class='ovr'\n",
    "model = LogisticRegression(multi_class='ovr')\n",
    "# definimos el porcedimiento de evaluación el modelo\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# Imprimimos la acuracidad del modelo obtenido\n",
    "print('Acuracidad media: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La clase OneVsRestClassifier.\n",
    "\n",
    "Scikit learn tiene una clase propia para hacer este tipo de clasificaciones múltiples: <a href=\"\" target=\"_blank\">OneVsRestClassifier</a>, mediante la cual se puede utilizar esta estrategia con cualquier clasificador  de los comunmente utilizados. A continuación se muestra un ejemplo de su uso, utilizando una regresión logística como clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.686 (0.036)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# importamos OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5,\n",
    "n_classes=3, random_state=1)\n",
    "\n",
    "model = LogisticRegression()\n",
    "# indicamos a la clase OneVsRestClassifier el modelo a utilizar\n",
    "ovr = OneVsRestClassifier(estimator = model)\n",
    "# hacemos la evaluación del modelo\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "n_scores = cross_val_score(ovr, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se usa el modelo OvR, se puede utilizar el mismo para hacer predicciones de forma similar a como se utiliza cualquier otro clasificador, utilizando para ello el método *predict*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clase predicha: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5,\n",
    "n_classes=3, random_state=1)\n",
    "# modelo base\n",
    "model = LogisticRegression()\n",
    "# \n",
    "ovr = OneVsRestClassifier(model)\n",
    "# ajuste del modelo\n",
    "ovr.fit(X, y)\n",
    "# valores para predicción\n",
    "row = [1.89149379, -0.39847585, 1.63856893, 0.01647165, 1.51892395, -3.52651223,\n",
    "1.80998823, 0.58810926, -0.02542177, -0.52835426]\n",
    "yhat = ovr.predict([row])\n",
    "print('clase predicha: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Vs-One para clasificación múltiple (OvO).\n",
    "\n",
    "Constituye otro método heurístico para hacer clasificaciones múltiples vía clasificaciones binarias. En esta ocasión, las clasificaciones binarias se realizan utilizando todos los pares posibles de clases que se puedan hacer, y en este sentido si las clases de la variable clasificadora son rojo, azul y amarillo, entonces las clasificaciones binarias a realizar serían los pares siguientes:\n",
    "\n",
    "* rojo vs azul\n",
    "\n",
    "* rojo vs amarillo\n",
    "\n",
    "* azul vs amarillo\n",
    "\n",
    "En este sentido y teniendo esto en cuenta, el número de modelos a ajustar sería combinaciones de m tomados de dos en dos, siendo m el número de clases que tiene la variable clasificadora. Ese valor por lo tanto sería igual a m*(m-1)/2.\n",
    "\n",
    "La decisión final que se toma con este método, sería bien la clase más votada o bien si el método utilizado produce un scores ( o probabilidad) entonces la clase elegida será la que tenga mayor suma de scores. \n",
    "\n",
    "En scikit learn, se puede ver que la clase SVC (support vector machine) tiene un parámetro para indicar que se quiere utilizar este tipo de clasificación. Esto se puede ver en el siguiente ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracidad media: 0.871 (0.028)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5,\n",
    "n_classes=3, random_state=1)\n",
    "# definimos el modelo e indicamos que utilice una clasificación \n",
    "model = SVC(decision_function_shape='ovo')\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluamos el modelo\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# resumen de la acuracidad\n",
    "print('Acuracidad media: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que ocurría con la clasificación OvR, scikit learn tiene una clase genérica que permite hacer clasificaciones del tipo One vs One, la clase se denomina OneVsOneClassifier, y a continuación se muestra un ejemplo, explicativo de su uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracidad Media: 0.872 (0.030)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5,\n",
    "n_classes=3, random_state=1)\n",
    "\n",
    "\n",
    "model = SVC()\n",
    "# definimos la estrategia OvO\n",
    "ovo = OneVsOneClassifier(model)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "n_scores = cross_val_score(ovo, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('Acuracidad Media: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es de esperar también se pueden hacer predicciones, utilizando para ello el método *predict*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase predicha: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5,\n",
    "n_classes=3, random_state=1)\n",
    "\n",
    "model = SVC()\n",
    "\n",
    "ovo = OneVsOneClassifier(model)\n",
    "\n",
    "ovo.fit(X, y)\n",
    "# tomamos dato para hacer predicción\n",
    "row = [1.89149379, -0.39847585, 1.63856893, 0.01647165, 1.51892395, -3.52651223,\n",
    "1.80998823, 0.58810926, -0.02542177, -0.52835426]\n",
    "yhat = ovo.predict([row])\n",
    "print('Clase predicha: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
